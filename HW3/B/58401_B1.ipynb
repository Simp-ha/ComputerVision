{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XCOYuc9LGgKu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "if os.path.exists('imagedb_btsd.zip'):\n",
    "  if os.path.isdir('imagedb'):\n",
    "    print('imagedb already exists')\n",
    "  else:\n",
    "    local_zip = 'imagedb_btsd.zip'\n",
    "    zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "    # zip_ref.extractall('/content')\n",
    "    zip_ref.extractall('./')\n",
    "    zip_ref.close()\n",
    "else:\n",
    "  print('imagedb_btsd.zip not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0s99AxKpG0MR"
   },
   "outputs": [],
   "source": [
    "train_dir = 'imagedb'\n",
    "test_dir = 'imagedb_test'\n",
    "\n",
    "# train_dir = os.path.join(train_dir)\n",
    "# test_dir = os.path.join(test_dir)\n",
    "# validation_dir = os.path.join(base_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bIHqZI8y3uy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(123)\n",
    "train_datagen = ImageDataGenerator( rescale=1./255, validation_split=0.2,\n",
    "                                   rotation_range=10,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   zoom_range=0.1)\n",
    "test_datagen = ImageDataGenerator( rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# --------------------\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "# --------------------\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=128,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(128,128),\n",
    "                                                    subset='training')\n",
    "# --------------------\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "# --------------------\n",
    "validation_generator =  test_datagen.flow_from_directory(train_dir,\n",
    "                                                         batch_size=128,\n",
    "                                                         class_mode  = 'categorical',\n",
    "                                                         color_mode='rgb',\n",
    "                                                         target_size=(128,128),\n",
    "                                                         subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "yN-vHOJotPVh"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(16, (5, 5), strides=(1, 1), activation='relu', input_shape=(128, 128, 3)),\n",
    "  tf.keras.layers.Conv2D(32, (3, 3), strides=(1, 1), activation='relu', input_shape=(128, 128, 3)),\n",
    "  tf.keras.layers.Conv2D(64, (3, 3), strides=(1, 1), activation='relu', input_shape=(128, 128, 3)),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(100, activation='relu'),\n",
    "  tf.keras.layers.Dense(34, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzsPPVGEtUHA"
   },
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "save_best_callback = tf.keras.callbacks.ModelCheckpoint(f'best_weights.keras',\n",
    "                                                        save_best_only=True,\n",
    "                                                        verbose=1)\n",
    "callbacks.append(save_best_callback)\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, verbose=1)\n",
    "callbacks.append(early_stop_callback)\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                              validation_data=validation_generator,\n",
    "                              steps_per_epoch=int(train_generator.samples/train_generator.batch_size),\n",
    "                              epochs=50,\n",
    "                              validation_steps=15,\n",
    "                              verbose=1,\n",
    "                              callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zg02-bC4tW9w"
   },
   "outputs": [],
   "source": [
    "test_datagen  = ImageDataGenerator()\n",
    "# test_dir = os.path.join(test_dir, 'test')\n",
    "test_generator =  test_datagen.flow_from_directory(test_dir,\n",
    "                                                   batch_size=128,\n",
    "                                                   class_mode  = 'categorical',\n",
    "                                                   color_mode='rgb',\n",
    "                                                   target_size=(128,128))\n",
    "loss, acc = model.evaluate(test_generator)\n",
    "ff = open(\"Results.txt\", \"a\")\n",
    "ff.write(f\"Accuracy of the model is: {round(acc*100,5)}%\")\n",
    "ff.write(f\"\\nLoss of the model is: {round(loss,5)}\\n\\n\")\n",
    "ff.close()\n",
    "\n",
    "ff = open(\"Results.txt\", \"r\")\n",
    "print(ff.read())\n",
    "ff.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "PbVeWYpUIxQq"
   },
   "outputs": [],
   "source": [
    "from posix import waitid_result\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.utils import load_img, img_to_array\n",
    "import numpy as np\n",
    "counter = 0\n",
    "# for every class in train_dir\n",
    "for s in os.listdir(train_dir):\n",
    "  image = []\n",
    "  for img in os.listdir(os.path.join(train_dir, s)):\n",
    "    img_path = os.path.join(train_dir, s, img)\n",
    "    # img = mpimg.imread(img_path)\n",
    "    # image.append(img)\n",
    "    counter += 1\n",
    "    # plt.imshow(img, cmap='gray')\n",
    "    # plt.show()\n",
    "  # signs.append(image)\n",
    "# print(counter)\n",
    "\n",
    "# Just an example...\n",
    "path = '/content/imagedb_test/00053/00001_00001.ppm'\n",
    "img = load_img(path, target_size=(128, 128), interpolation='bilinear')\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "x = img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "classes_pred = model.predict(x)\n",
    "dir = os.listdir(test_dir)\n",
    "dir.sort()\n",
    "classes = [s for s in dir]\n",
    "print(f'\\n\\n\\n{classes}')\n",
    "print(f'\\n\\n\\nSoftmax Output: {classes_pred}')\n",
    "print(f'\\n\\n\\n{path} is a {classes[classes_pred.argmax()]}\\n\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
